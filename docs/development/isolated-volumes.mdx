---
title: "Isolated Volumes"
description: "How ShipSec Studio keeps every workflow run's files completely separate — even when running Docker inside Docker."
---

## The Problem This Solves

ShipSec Studio runs security tools inside Docker containers. But there's a catch — the worker itself also runs inside Docker. This "Docker-in-Docker" (DinD) setup breaks the normal way of sharing files with containers, and creates a serious security risk in multi-tenant environments.

Three problems needed solving:

- **Volume path mismatch** — file paths are relative to the host Docker daemon, not the worker container. Normal file mounts simply don't work.
- **Cross-tenant data leakage** — shared volumes mean one tenant's files could be visible to another's.
- **No stdin fallback** — many security tools only accept file-based input, so piping data in via stdin isn't an option.

---

## The Solution: One Volume Per Run

Every workflow execution gets its own **unique, isolated Docker named volume** — tied to the tenant ID, run ID, and a timestamp:
```
tenant-{tenantId}-run-{runId}-{timestamp}

# Example
tenant-acme-run-wf-abc123-1732150000
```

It's created before the tool runs, mounted into the container, read after execution, then **immediately destroyed**. No shared state. No leftovers.

---

## How It Works — Step by Step
```
Docker Host
└── Worker Container (DinD)
    │
    ├── 1. CREATE volume
    │      docker volume create tenant-A-run-1-...
    │
    ├── 2. POPULATE files via temp Alpine container
    │      docker run -v vol:/data alpine sh -c "echo ... > /data/domains.txt"
    │
    ├── 3. RUN the security tool with volume mounted
    │      docker run -v vol:/inputs dnsx ...
    │
    ├── 4. READ output files via temp Alpine container
    │      docker run -v vol:/data alpine cat /data/results.json
    │
    └── 5. DESTROY the volume
           docker volume rm tenant-A-run-1-...

Docker Host — Named Volumes (completely separate per tenant + run)
├── tenant-A-run-123-1732090000
├── tenant-B-run-456-1732090001
└── tenant-A-run-789-1732090002
```

---

## Security Improvements

| Aspect | Old Approach | Isolated Volumes |
|---|---|---|
| **Tenant Isolation** | ❌ Shared volume or stdin | ✅ Unique volume per tenant + run |
| **Path Traversal** | ⚠️ Possible with file mounts | ✅ Filenames validated — no `..` or `/` |
| **Data Leakage** | ❌ Files persist in shared space | ✅ Destroyed immediately after use |
| **Audit Trail** | ❌ None | ✅ Every volume labeled `studio.managed=true` |
| **DinD Compatible** | ❌ File mounts break | ✅ Named volumes work perfectly |

---

## Approach Comparison

Not sure which approach fits your use case? Here's the full breakdown:

| Feature | File Mounts | stdin | Isolated Volumes |
|---|---|---|---|
| **DinD Compatible** | ❌ | ✅ | ✅ |
| **File-based tools** | ✅ | ❌ | ✅ |
| **Config files** | ✅ | ❌ | ✅ |
| **Output files** | ❌ Hard | ❌ | ✅ |
| **Binary / large files** | ✅ | ⚠️ Memory limits | ✅ |
| **Tenant isolation** | ❌ | ⚠️ Process-level only | ✅ Volume-level |

---

## Code Examples

### Before — File Mounts (Broken in DinD)
```typescript
// ❌ WRONG — breaks in DinD, no tenant isolation
const hostInputDir = await mkdtemp(path.join(tmpdir(), 'dnsx-input-'));
await writeFile(path.join(hostInputDir, 'file.txt'), data);

const runnerConfig: DockerRunnerConfig = {
  volumes: [
    { source: hostInputDir, target: '/inputs', readOnly: true }
  ]
};
```

### After — Isolated Volumes (DinD Compatible)
```typescript
// ✅ CORRECT — DinD compatible, fully tenant isolated
const tenantId = context.tenantId ?? 'default-tenant';
const volume = new IsolatedContainerVolume(tenantId, context.runId);

try {
  await volume.initialize({
    'domains.txt': domains.join('\n'),
    'resolvers.txt': resolvers.join('\n')
  });

  const runnerConfig: DockerRunnerConfig = {
    volumes: [volume.getVolumeConfig('/inputs', true)] // read-only
  };

  await runComponentWithRunner(runnerConfig, ...);

  const outputs = await volume.readFiles(['results.json']);

} finally {
  await volume.cleanup(); // Always runs — even if an error is thrown
}
```

---

### Input + Output Files

When the tool needs to both read inputs *and* write outputs to the same volume:
```typescript
const volume = new IsolatedContainerVolume(tenantId, runId);

try {
  await volume.initialize({
    'config.yaml': yamlConfig
  });

  const config = {
    command: ['--input', '/data/config.yaml', '--output', '/data/results.json'],
    volumes: [volume.getVolumeConfig('/data', false)] // read-write
  };

  await runTool(config);

  const outputs = await volume.readFiles(['results.json', 'summary.txt']);
  return JSON.parse(outputs['results.json']);

} finally {
  await volume.cleanup();
}
```

---

### Separate Input and Output Volumes

For maximum isolation, use two volumes — one read-only for inputs, one write-only for outputs:
```typescript
const inputVol  = new IsolatedContainerVolume(tenantId, `${runId}-in`);
const outputVol = new IsolatedContainerVolume(tenantId, `${runId}-out`);

try {
  await inputVol.initialize({ 'data.csv': csvData });
  await outputVol.initialize({}); // empty — just here to receive output

  const config = {
    volumes: [
      inputVol.getVolumeConfig('/inputs', true),   // read-only
      outputVol.getVolumeConfig('/outputs', false)  // read-write
    ]
  };

  await runTool(config);

  const results = await outputVol.readFiles(['output.json']);

} finally {
  await Promise.all([inputVol.cleanup(), outputVol.cleanup()]);
}
```

---

## Security Details

### Path Validation

Filenames passed to `initialize()` are automatically validated. Anything that looks like a path traversal attempt is rejected before it ever reaches Docker.
```typescript
// ✅ These are fine
await volume.initialize({
  'file.txt': data,
  'subdir/file.txt': data
});

// ❌ These are blocked automatically
await volume.initialize({
  '../file.txt': data,  // path traversal — rejected
  '/etc/passwd': data   // absolute path — rejected
});
```

### Read-Only vs Read-Write Mounts
```typescript
volume.getVolumeConfig('/inputs', true)   // ✅ read-only  — use for input files
volume.getVolumeConfig('/outputs', false) // ⚠️ read-write — only when tool must write output
```

<Tip>
  Default to read-only. Only grant write access when the tool explicitly needs to produce output files.
</Tip>

### Nonroot Container Support

Some tools (like distroless images) run as a nonroot user (`uid 65532`). Files written to volumes via Alpine (which runs as root) would be unreadable by these containers.

`volume.initialize()` automatically runs `chmod -R 777` on the volume after writing files. This is safe because:
- Each volume is scoped to a single tenant + run
- Volumes are destroyed immediately after execution
- No cross-tenant access is ever possible

---

## Cleanup

### Automatic Cleanup (Normal Flow)

Volumes are always destroyed via `finally` blocks — even if the tool crashes or throws an error:
```typescript
try {
  await volume.initialize(...);
  await runTool(...);
} finally {
  await volume.cleanup(); // guaranteed to run
}
```

### Orphan Cleanup (After a Worker Crash)

If the worker process itself crashes mid-execution, volumes may be left behind. Clean them up with:
```bash
# List all volumes managed by ShipSec Studio
docker volume ls --filter "label=studio.managed=true"

# Remove all orphaned managed volumes
docker volume prune --filter "label=studio.managed=true"
```

---

## Performance

Volume creation adds a small, predictable overhead:

| Operation | Typical Duration |
|---|---|
| Volume creation | ~50–100ms |
| File writes | ~10–50ms per file |
| Volume cleanup | ~50–100ms |
| **Total overhead** | **~100–250ms** |

This is negligible for security tools that typically run for seconds or minutes.

**Tips to minimize overhead:**
- Write all files in a single `initialize()` call — don't call it multiple times
- Reuse the same volume for sequential steps within the same run
- Run `cleanup()` in the background if you're latency-sensitive and don't need to await it

---

## When to Use Each Approach

<CardGroup cols={3}>
  <Card title="Use Isolated Volumes" icon="shield-check">
    Running in DinD · Multi-tenant environment · Tool needs config files · Tool writes output files · Binary or large file handling
  </Card>
  <Card title="Use stdin / stdout" icon="terminal">
    Tool supports stdin input · Single-tenant or local dev · Small text-only data · No output files needed
  </Card>
  <Card title="Use File Mounts" icon="folder">
    NOT running in DinD · Local development only · Quick prototyping · Not going to production
  </Card>
</CardGroup>

---

## Migration Checklist

Migrating an existing component to use isolated volumes:

- [ ] Import `IsolatedContainerVolume`
- [ ] Get `tenantId` from `context.tenantId` (with a fallback for local dev)
- [ ] Create an instance: `new IsolatedContainerVolume(tenantId, runId)`
- [ ] Replace manual file writes with `volume.initialize({ files })`
- [ ] Replace volume mount config with `volume.getVolumeConfig()`
- [ ] Wrap execution in a `try/finally` block with `volume.cleanup()` in `finally`
- [ ] If the tool writes outputs, use `volume.readFiles([...])` to retrieve them
- [ ] Test end-to-end in a DinD environment before shipping

---

<CardGroup cols={2}>
  <Card title="Component Development" icon="arrow-left" href="/development/component-development">
    ← Previous
  </Card>
  <Card title="Workflow Analytics" icon="arrow-right" href="/development/workflow-analytics">
    Next →
  </Card>
</CardGroup>