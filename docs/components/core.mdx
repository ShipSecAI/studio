---
title: "Core Components"
description: "The essential building blocks for starting workflows, moving data, transforming it, and storing results."
---

Core components are the **glue of every workflow**. They handle how a workflow starts, how data moves between steps, how secrets are accessed, and where results end up. Every workflow you build will use at least a few of these.

---

## Triggers

Triggers are always the **first component** in a workflow. Nothing runs until a trigger fires.

### Manual Trigger

The simplest way to start a workflow — you click **Run**, fill in any required inputs, and it kicks off.

| Parameter | Type | What it does |
|---|---|---|
| `runtimeInputs` | JSON | Define what fields to show the user at runtime (files, text, numbers, etc.) |

**Supported input types:** `file` · `text` · `number` · `json` · `array`

**Good for:**
- Asking an operator to upload a scope file before a scan starts
- Prompting for a target domain or API key right before execution

---

### Webhook

Fires a workflow automatically when an external system sends an HTTP request to a generated URL.

| Parameter | Type | What it does |
|---|---|---|
| `url` | URL | Where to send the request |
| `method` | Select | `POST`, `PUT`, or `PATCH` |
| `payload` | JSON | The request body |
| `headers` | JSON | Any custom HTTP headers |
| `timeoutMs` | Number | How long to wait before giving up (default: `30000` ms) |
| `retries` | Number | How many times to retry on failure (default: `3`) |

**Good for:**
- Automatically triggering a scan when a new asset is added to your system
- Posting scan results to a custom internal API

---

## File Operations

### File Loader

Loads a previously uploaded file from storage so its contents can flow into the rest of your workflow.

| Input | Type | Description |
|---|---|---|
| `fileId` | UUID | The ID of the file you want to load |

| Output | Type | Description |
|---|---|---|
| `file` | Object | File metadata plus base64-encoded content |
| `textContent` | String | The file's contents as plain readable text |

---

### Text Splitter

Takes a block of text and breaks it into a list of items — like splitting a list of domains by line.

| Parameter | Type | What it does |
|---|---|---|
| `text` | String / File | The text you want to split |
| `separator` | String | What character to split on (default: `\n` — new line) |

| Output | Type | Description |
|---|---|---|
| `items` | Array | The list of split strings |
| `count` | Number | How many items were produced |

<Tip>
  Use this after **File Loader** to turn a newline-separated list of domains into an array you can pass to a scanner.
</Tip>

---

### Text Joiner

The opposite of Text Splitter — takes a list of items and merges them into one string.

| Parameter | Type | What it does |
|---|---|---|
| `items` | Array | The list of strings to join |
| `separator` | String | What to put between each item (default: `\n`) |

| Output | Type | Description |
|---|---|---|
| `text` | String | The combined result |

---

## Secrets

### Secret Loader

Safely fetches a stored secret (API key, password, token) from ShipSec's encrypted secret store and makes it available to downstream components — **without ever exposing the value in logs.**

| Parameter | Type | What it does |
|---|---|---|
| `secretName` | Secret | The name or UUID of the secret to fetch |
| `version` | Number | Pin to a specific version (optional) |
| `outputFormat` | Select | `raw` for plain text, `json` for parsed object |

| Output | Type | Description |
|---|---|---|
| `secret` | Any | The secret value — automatically masked in all logs |
| `metadata` | Object | Version info and metadata about the secret |

<Note>
  Secret values are **automatically redacted** from all logs, terminal output, and trace events. They are never stored in plain text.
</Note>

---

## Data Transformation

These components let you reshape, filter, and debug data as it flows through your workflow.

### Array Pick

Pulls specific items out of an array by their position (index).

| Parameter | Type | What it does |
|---|---|---|
| `array` | Array | The source list |
| `indices` | Array | Which positions to extract (e.g. `[0, 2, 4]`) |

| Output | Type | Description |
|---|---|---|
| `picked` | Array | Just the items you selected |

---

### Array Pack

Bundles multiple separate values into a single array — useful when you need to combine outputs from different components.

| Parameter | Type | What it does |
|---|---|---|
| `values` | Any[] | The values to bundle together |

| Output | Type | Description |
|---|---|---|
| `array` | Array | The combined array |

---

### Console Log

Prints data to the workflow's log panel. Use this when you're building or debugging a workflow and want to inspect what's flowing between steps.

| Parameter | Type | What it does |
|---|---|---|
| `data` | Any | The value you want to inspect |
| `label` | String | An optional label to identify the log entry |

<Info>
  Console Log doesn't affect your workflow's execution — it's purely for visibility. Remove it before running workflows in production.
</Info>

---

## Storage & Destinations

Where your workflow results end up.

### Artifact Writer

Saves a file or data blob to ShipSec's built-in storage, making it downloadable from the workflow run page.

| Parameter | Type | What it does |
|---|---|---|
| `content` | Any | The data to store |
| `filename` | String | What to name the file |
| `mimeType` | String | The file type (e.g. `text/plain`, `application/json`) |

| Output | Type | Description |
|---|---|---|
| `artifactId` | UUID | A unique ID for the stored artifact |
| `url` | String | A direct download URL |

---

### File Writer

Writes raw text content to a file path in workflow storage.

| Parameter | Type | What it does |
|---|---|---|
| `content` | String | The text to write |
| `path` | String | Where to save it (e.g. `results/output.txt`) |

---

### Destination S3

Uploads a file directly to any S3-compatible bucket (AWS S3, MinIO, Cloudflare R2, etc.).

| Parameter | Type | What it does |
|---|---|---|
| `bucket` | String | The bucket name |
| `key` | String | The object path/key inside the bucket |
| `content` | Buffer | The file content to upload |
| `credentials` | Object | AWS credentials (use **AWS Credentials** component) |

---

### AWS Credentials

Provides AWS credentials to other components that need them (like **Destination S3**). Connect its output to the `credentials` input of any AWS-powered component.

| Parameter | Type | What it does |
|---|---|---|
| `accessKeyId` | Secret | Your AWS Access Key ID |
| `secretAccessKey` | Secret | Your AWS Secret Access Key |
| `region` | String | AWS region (e.g. `us-east-1`) |

| Output | Type | Description |
|---|---|---|
| `credentials` | Object | A credentials object ready to plug into S3 components |

<Tip>
  Always use the **Secret Loader** to supply `accessKeyId` and `secretAccessKey` — never paste keys directly into parameters.
</Tip>

---

## Analytics

### Analytics Sink

Sends workflow output data into **OpenSearch** so you can query it, visualize it in dashboards, and track findings over time. Connect it to the `results` port of any scanner.

| Input | Type | Description |
|---|---|---|
| `data` | Any | The data to index — works best with `list<json>` from scanner `results` ports |

| Output | Type | Description |
|---|---|---|
| `indexed` | Boolean | Whether indexing succeeded |
| `documentCount` | Number | How many records were indexed |
| `indexName` | String | The OpenSearch index that was used |

| Parameter | Type | What it does |
|---|---|---|
| `indexSuffix` | String | Custom suffix appended to the index name. Defaults to the workflow name. |
| `assetKeyField` | Select | Which field to use as the asset identifier. Options: `auto`, `host`, `domain`, `subdomain`, `url`, `ip`, `asset`, `target`, `custom` |
| `customAssetKeyField` | String | Your own field name when `assetKeyField` is set to `custom` |
| `failOnError` | Boolean | If `true`, the workflow stops when indexing fails. Default: `false` (fire-and-forget) |

**How it works behind the scenes:**

1. Each item in the input array becomes its own searchable document
2. Workflow metadata is added automatically under the `shipsec.*` namespace
3. Nested objects are serialized to prevent index field explosion
4. All documents share the same `@timestamp` for time-series querying

**Good for:**
- Tracking Nuclei vulnerability findings over time
- Storing TruffleHog secrets for audit trails
- Aggregating results across multiple workflows into one dashboard

<Note>
  Analytics Sink requires OpenSearch to be configured. See the [Workflow Analytics](/development/workflow-analytics) guide for full setup instructions.
</Note>

---

<CardGroup cols={2}>
  <Card title="Components Overview" icon="arrow-left" href="/components/overview">
    ← Previous
  </Card>
  <Card title="Security Components" icon="arrow-right" href="/components/security">
    Next →
  </Card>
</CardGroup>